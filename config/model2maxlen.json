{
    "llama2-7b-chat-4k": 4096,
    "llama2-13b": 4096,
    "codellama-13b-instruct": 4096,
    "toolllama-2-7b": 4096,
    "longchat-v1.5-7b-32k": 31500,
    "xgen-7b-8k": 7500,
    "internlm-7b-8k": 2048,
    "chatglm2-6b": 31500,
    "chatglm2-6b-32k": 31500,
    "vicuna-v1.5-7b-16k": 15500,
    "tulu-7b": 2048,
    "vicuna-13b": 2048,
    "gpt-3.5-turbo-1106": 16000,
    "gpt-4-1106-preview": 128000
}